{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Research Methods Report-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**<br>\n",
    "The PAMAP2 Physical Activity Monitoring dataset (available here) contains data from 9 participants who participated in 18 various physical activities (such as walking, cycling, and soccer) while wearing three inertial measurement units (IMUs) and a heart rate monitor. This information is saved in separate text files for each subject. The goal is to build hardware and/or software that can determine the amount and type of physical activity performed by an individual by using insights derived from analysing the given dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import tabula\n",
    "from IPython.display import display\n",
    "from matplotlib import rcParams\n",
    "from scipy.stats import ranksums,ttest_ind\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import itertools\n",
    "os.chdir(\"/home/sahil/Downloads/PAMAP2_Dataset/\") # Setting up working directory\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning<br>\n",
    "For tidying up the data :<br>\n",
    "- We load the data of various subjects and give relevant column names<br>\n",
    "  for various features. <br>\n",
    "- The data for all subjects are then stacked together to form one table.<br>\n",
    "- We remove the 'Orientation' columns because it was mentioned <br>\n",
    "  in the data report that it is invalid in this data collection.<br>\n",
    "- Similarly, the rows with Activity ID \"0\" are also removed as<br>\n",
    "  it does not relate to any specific activity.<br>\n",
    "- The missing values are filled up using the linear interpolation method.<br>\n",
    "- Added a new feature, 'BMI' or Body Mass Index for the 'subject_detail' table<br>\n",
    "- Additional feature, 'Activity Type' is added to the data which classifies activities <br>\n",
    "  into 3 classes, 'Light' activity,'Moderate' activity and 'Intense' activity.<br>\n",
    "  1. Lying,sitting,ironing and standing are labelled as 'light' activities.<br>\n",
    "  2. Vacuum cleaning,descending stairs,normal walking,Nordic walking and cycling are<br>\n",
    "     considered as 'Moderate' activities<br>\n",
    "  3. Ascending stairs,running and rope jumping are labelled as 'Intense' activities.  <br>\n",
    "  This classification makes it easier to perform hypothesis testing between pair of attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "Given below are functions to give relevant names to the columns and create a<br>\n",
    "single table containing data for all subjects<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_activity_names():\n",
    "    # Using this function all the activity names are mapped to their ids\n",
    "    act_name = {}\n",
    "    act_name[0] = 'transient'\n",
    "    act_name[1] = 'lying'\n",
    "    act_name[2] = 'sitting'\n",
    "    act_name[3] = 'standing'\n",
    "    act_name[4] = 'walking'\n",
    "    act_name[5] = 'running'\n",
    "    act_name[6] = 'cycling'\n",
    "    act_name[7] = 'Nordic_walking'\n",
    "    act_name[9] = 'watching_TV'\n",
    "    act_name[10] = 'computer_work'\n",
    "    act_name[11] = 'car driving'\n",
    "    act_name[12] = 'ascending_stairs'\n",
    "    act_name[13] = 'descending_stairs'\n",
    "    act_name[16] = 'vacuum_cleaning'\n",
    "    act_name[17] = 'ironing'\n",
    "    act_name[18] = 'folding_laundry'\n",
    "    act_name[19] = 'house_cleaning'\n",
    "    act_name[20] = 'playing_soccer'\n",
    "    act_name[24] = 'rope_jumping'\n",
    "    return act_name\n",
    "def generate_three_IMU(name):\n",
    "    x = name +'_x'\n",
    "    y = name +'_y'\n",
    "    z = name +'_z'\n",
    "    return [x,y,z]\n",
    "def generate_four_IMU(name):\n",
    "    x = name +'_x'\n",
    "    y = name +'_y'\n",
    "    z = name +'_z'\n",
    "    w = name +'_w'\n",
    "    return [x,y,z,w]\n",
    "def generate_cols_IMU(name):\n",
    "    # temp\n",
    "    temp = name+'_temperature'\n",
    "    output = [temp]\n",
    "    # acceleration 16\n",
    "    acceleration16 = name+'_3D_acceleration_16'\n",
    "    acceleration16 = generate_three_IMU(acceleration16)\n",
    "    output.extend(acceleration16)\n",
    "    # acceleration 6\n",
    "    acceleration6 = name+'_3D_acceleration_6'\n",
    "    acceleration6 = generate_three_IMU(acceleration6)\n",
    "    output.extend(acceleration6)\n",
    "    # gyroscope\n",
    "    gyroscope = name+'_3D_gyroscope'\n",
    "    gyroscope = generate_three_IMU(gyroscope)\n",
    "    output.extend(gyroscope)\n",
    "    # magnometer\n",
    "    magnometer = name+'_3D_magnetometer'\n",
    "    magnometer = generate_three_IMU(magnometer)\n",
    "    output.extend(magnometer)\n",
    "    # oreintation\n",
    "    oreintation = name+'_4D_orientation'\n",
    "    oreintation = generate_four_IMU(oreintation)\n",
    "    output.extend(oreintation)\n",
    "    return output\n",
    "def load_IMU():\n",
    "    output = ['time_stamp','activity_id', 'heart_rate']\n",
    "    hand = 'hand'\n",
    "    hand = generate_cols_IMU(hand)\n",
    "    output.extend(hand)\n",
    "    chest = 'chest'\n",
    "    chest = generate_cols_IMU(chest)\n",
    "    output.extend(chest)\n",
    "    ankle = 'ankle'\n",
    "    ankle = generate_cols_IMU(ankle)\n",
    "    output.extend(ankle)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subjects(root1='/home/sahil/Downloads/PAMAP2_Dataset/Protocol/subject',\n",
    "        root2 ='/home/sahil/Downloads/PAMAP2_Dataset/Optional/subject' ):\n",
    "    cols = load_IMU()\n",
    "    output = pd.DataFrame()\n",
    "    for i in range(101,110):\n",
    "        path1 = root1 + str(i) + '.dat'\n",
    "        subject= pd.DataFrame()\n",
    "         \n",
    "        subject_prot = pd.read_table(path1, header=None, sep='\\s+') # subject data from \n",
    "         # protocol activities\n",
    "        subject = subject.append(subject_prot)\n",
    "        subject.columns = cols \n",
    "        subject = subject.sort_values(by='time_stamp') # Arranging all measurements according to\n",
    "         # time\n",
    "        subject['id'] = i\n",
    "        output = output.append(subject, ignore_index=True)\n",
    "    return output\n",
    "data = load_subjects()# Add your own location for the data here to replicate the code\n",
    "# for eg data = load_subjects('filepath')\n",
    "data = data.drop(data[data['activity_id']==0].index)# Removing rows with activity id of 0\n",
    "act = gen_activity_names()\n",
    "data['activity_name'] = data.activity_id.apply(lambda x:act[x])\n",
    "data = data.drop([i for i in data.columns if 'orientation' in i], axis=1)  # Dropping Orientation  columns\n",
    "cols_6g = [i for i in data.columns if '_6_' in i] # 6g acceleration data columns\n",
    "data =  data.drop(cols_6g,axis=1) # dropping 6g acceleration columns\n",
    "display(data.head())\n",
    "# Saving transformed data in pickle format becuse it has the fastest read time compared\n",
    "# to all other formats\n",
    "data.to_pickle(\"activity_data.pkl\")  # Saving transformed data for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data,split_size):\n",
    "    np.random.seed(5)\n",
    "    msk = np.random.rand(len(data)) < split_size # This code implies (split_size*100)% of the values will be True\n",
    "    train = data[msk] # Generating training data\n",
    "    test = data[~msk] # generating testing data  \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_subjects(data): # splitting by subjects\n",
    "    subjects = [i for i in range(101,109)] # Eliminate subject 109  due to less activities\n",
    "    train_subjects = [101,103,104,105]\n",
    "    test_subjects = [i for i in subjects if i not in train_subjects]\n",
    "    train = data[data.id.isin(train_subjects)] # Generating training data\n",
    "    test = data[data.id.isin(test_subjects)] # generating testing data  \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_activities(data):\n",
    "   light = ['lying','sitting','standing','ironing'] \n",
    "   moderate = ['vacuum_cleaning','descending_stairs','normal_walking',\n",
    "           'nordic_walking','cycling']\n",
    "   intense = ['ascending_stairs','running','rope_jumping']\n",
    "   def split(activity): #  method for returning activity labels for activities\n",
    "       if activity in light:\n",
    "           return 'light'\n",
    "       elif activity in moderate:\n",
    "           return 'moderate'\n",
    "       else:\n",
    "           return 'intense'\n",
    "   data['activity_type'] = data.activity_name.apply(lambda x:split(x))\n",
    "   return data\n",
    "def split_by_activities_6(data):\n",
    "   main = ['lying','sitting','standing','walking','running','cycling'] \n",
    "   others = [i for i in data.activity_name.unqiue() if i not in main]\n",
    "   sit_stand = ['sitting','standing']\n",
    "   if activity in main:\n",
    "       if activity in sit_stand:\n",
    "           return 'sitting/standing'\n",
    "       else:\n",
    "           return activity\n",
    "   else:\n",
    "       return 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_subset(data,subset_frac): # For selecting a random subset of data\n",
    "    np.random.seed(8)\n",
    "    msk = np.random.rand(len(data)) < subset_frac # This code implies (split_size*100)% of the values will be True\n",
    "    subset = data[msk] # Generating subset\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data and doing the train-test split for EDA and Hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"activity_data.pkl\")\n",
    "data = split_by_activities(data)\n",
    "train,test = train_test_split_by_subjects(data) # train and test data for EDA and hypothesis testing respectively.\n",
    "subj_det = tabula.read_pdf(\"subjectInformation.pdf\",pages=1) # loading subject detail table from pdf file.\n",
    "# Eliminating unnecessary columns and fixing the column alignment of the table.\n",
    "sd = subj_det[0]\n",
    "new_cols = list(sd.columns)[1:9]\n",
    "sd = sd[sd.columns[0:8]]\n",
    "sd.columns = new_cols \n",
    "subj_det=sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create clean data for use in modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminate = ['activity_id','activity_name','time_stamp','id'] # Columns not meant to be cleaned\n",
    "features = [i for i in data.columns if i not in eliminate]\n",
    "clean_data = data\n",
    "clean_data[features] =clean_data[features].interpolate()\n",
    "display(clean_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After linear interpolation, the first four values of heart rate are still missing. So we fill that using back fill method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['heart_rate'] = clean_data['heart_rate'].bfill()\n",
    "display(clean_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the clean data for future use in model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.to_pickle(\"clean_act_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis<br>\n",
    "After labelling the data appropriately, we have selected 4 subjects for training set and <br>\n",
    "4 subjects for testing set such that the training and testing set have approximately equal size.<br>\n",
    "In the training set, we perform Exploratory Data Analysis and come up with potential hypotheses. <br>\n",
    "We then test those hypotheses on the testing set.<br>\n",
    "50% of data is used for training in this case(Exploratory data analysis) and the rest for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating BMI of the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_in_metres = subj_det['Height (cm)']/100\n",
    "weight_in_kg = subj_det['Weight (kg)']\n",
    "subj_det['BMI'] =  weight_in_kg/(height_in_metres)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bar chart for frequency of activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40,25\n",
    "ax=sns.countplot(x=\"activity_name\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3D scatter plot of chest acceleration coordinates for lying<br>\n",
    "<br>\n",
    "  It is expected that vertical chest acceleration will be more while lying due to the<br>\n",
    "  movements involved and an attempt is made to check this visually over here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "train_running = train[train.activity_name=='lying']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "x = train_running[\"chest_3D_acceleration_16_x\"]\n",
    "y = train_running[\"chest_3D_acceleration_16_y\"]\n",
    "z = train_running[\"chest_3D_acceleration_16_z\"]\n",
    "ax.scatter(x,y,z)\n",
    "ax.set_xlabel('X Axis')\n",
    "ax.set_ylabel('Y Axis')\n",
    "ax.set_zlabel('Z Axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   As we see, there seems to be more variance along the z axis(vertical direction) than the<br>\n",
    "   x and y axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3D scatter plot of chest acceleration coordinates for running<br>\n",
    "<br>\n",
    "  Since running involves mostly horizontal movements for the chest, we expect<br>\n",
    "  most of chest acceleration data to lie on the horizontal x amd y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "train_running = train[train.activity_name=='running']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "x = train_running[\"chest_3D_acceleration_16_x\"]\n",
    "y = train_running[\"chest_3D_acceleration_16_y\"]\n",
    "z = train_running[\"chest_3D_acceleration_16_z\"]\n",
    "ax.scatter(x,y,z)\n",
    "ax.set_xlabel('X Axis')\n",
    "ax.set_ylabel('Y Axis')\n",
    "ax.set_zlabel('Z Axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  As we expected, for running, most of the points lie along the x and y axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Time series plot of x axis chest acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "random.seed(4)\n",
    "train1 = train[train.id==random.choice(train.id.unique())]\n",
    "sns.lineplot(x='time_stamp',y='chest_3D_acceleration_16_z',hue='activity_name',data=train1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of rolling mean of vertical chest acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rolling_mean'] = train['chest_3D_acceleration_16_z'].rolling(256).mean()\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"rolling_mean\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of rolling mean of horizontal ankle acceleration along x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rolling_mean'] = train['ankle_3D_acceleration_16_x'].rolling(256).mean()\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"rolling_mean\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of rolling mean of horizontal ankle acceleration along y axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rolling_mean'] = train['ankle_3D_acceleration_16_y'].rolling(256).mean()\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"rolling_mean\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of heart rate grouped by activity type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15,10\n",
    "ax=sns.boxplot(x=\"activity_type\",y=\"heart_rate\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=0)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. We observe that moderate and intense activities have higher heart rate than<br>\n",
    "    light activities as expected.<br>\n",
    " 2. There doesn't seem to be much seperation between moderate and intesne activity<br>\n",
    "    heart rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of heart rate grouped by activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40,25\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"heart_rate\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1.  Most of the activities have a skewed distribution for heart rate.<br>\n",
    "  2. 'Nordic_walking','running' and 'cycling' have a lot of outliers on the lower side.<br>\n",
    "  3.  Activities like 'lying','sitting' and 'standing' have a lot of outliers on the upper side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of hand temperature grouped by activity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15,10\n",
    "ax=sns.boxplot(x=\"activity_type\",y=\"hand_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hand temperature of moderate activitie have a lot of outliers on the lower side.<br>\n",
    "2. There doesn't seem to be much difference in temperatures between activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of hand temperature grouped by activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40,25\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"hand_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hand temperature data of 'playing_soccer' seems to have a very pronounced positive skew.<br>\n",
    "2. \"car_driving\" and \"watching_tv\" have the least dispersion in hand temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of ankle temperature grouped by activity_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15,10\n",
    "ax=sns.boxplot(x=\"activity_type\",y=\"ankle_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ankle temperature of light and moderate activitie have  outliers on the lower side.<br>\n",
    "2. There doesn't seem to be much difference in temperatures between activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of ankle temperature grouped by activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40,25\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"ankle_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45) # Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For ankle temperature, 'playing_soccer' has the least dispersed distribution.<br>\n",
    "2. Outliers are mostly present in 'vacuum_cleaning' on the lower side. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of chest temperature grouped by activity_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15,10\n",
    "ax=sns.boxplot(x=\"activity_type\",y=\"chest_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For chest temperatures, only the 'intense' activity type has an outlier.<br>\n",
    "2. For this feature as well, there doesn't seem to be much difference between <br>\n",
    "   temperatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of chest temperature grouped by activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40,25\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"chest_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45) # Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Most of the activities seem to have a skewed distribution for chest temperature.<br>\n",
    "2. 'car_driving' and 'watching_tv' seem to have the least dispersed distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A joint plot trying to investigate possibility of correlation between heart rate <br>\n",
    "  and chest temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "rcParams['font.size'] = 20 # Setting the text and number font size\n",
    "g = sns.JointGrid(data=train, x=\"heart_rate\", y=\"chest_temperature\",\n",
    "                  height=10,ratio=3)\n",
    "g.plot_joint(sns.scatterplot,palette='colorblind')\n",
    "g.plot_marginals(sns.histplot)\n",
    "# ax.set_xticklabels(ax.get_xticklabels(),rotation=45) # Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the scatter plot, we see that there does not seem to be a correlation between<br>\n",
    "   the two variables.<br>\n",
    "2. The respective histograms indicate that both the features considered have <br>\n",
    "   a multi-modal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics<br>\n",
    "Subject Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(subj_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of heart rate and temperatures for each activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.groupby(by='activity_name')[['heart_rate','chest_temperature','hand_temperature',\n",
    "    'ankle_temperature']].mean())\n",
    "discard = ['activity_id','activity','time_stamp','id']# Columns to exclude from descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating table with only relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trimmed = train[[i for i in train.columns if i not in discard]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive info of relevant feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_trimmed.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation table of relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_trimmed.corr()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance of each axis of acceleration grouped by activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = [i for i in train.columns if 'acceleration' in i]\n",
    "display(train.groupby(by='activity_name')[coordinates].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the exploratory data analysis carried out, the following hypotheses are tested on  <br>\n",
    "the test set:<br>\n",
    "- Heart rate of moderate activities are greater than heart rate of light activities.<br>\n",
    "- Heart rate of intense activities are greater than heart rate of light activities.<br>\n",
    "- Chest acceleration along z axis is greater than that along x axis during lying.<br>\n",
    "- Chest acceleration along x axis is greater than that along z axis during running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the EDA  we performed, it does not seem that the data is normally distributed. It is <br>\n",
    "for this reason that Wilcoxon rank sum test was used to test the above hypothesis instead of the usual t-test which assumes that the samples follow a normal distribution.<br>\n",
    "We test the above hypothesis using the confidence level of 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 1<br>\n",
    "$H_0$(Null) : The heart rate during  moderate activities are the same or lower than that of light activities. <br>\n",
    "$H_1$(Alternate) : The heart rate during moderate activities are likely to be higher during lying compared to light activities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test[test.activity_type=='moderate'].heart_rate.dropna()# Heart rate of moderate activities with nan values dropped\n",
    "test2 = test[test.activity_type=='light'].heart_rate.dropna()# Heart rate of light activities with nan values dropped\n",
    "print(ranksums(test1,test2,alternative='greater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 2<br>\n",
    "$H_0$(Null) : The heart rate during intense activities are the same or lower than that of light activities. <br>\n",
    "$H_1$(Alternate) : The heart rate during intense activities are likely to be higher during than during lower activities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test[test.activity_type=='intense'].heart_rate.dropna()# Heart rate of moderate activities with nan values dropped\n",
    "test2 = test[test.activity_type=='light'].heart_rate.dropna()# Heart rate of light activities with nan values dropped\n",
    "print(ranksums(test1,test2,alternative='greater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we get a p-value of 0 which is lower than 0.05 we reject the null hypothesis and accept<br>\n",
    "the alternate hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 3<br>\n",
    "$H_0$(Null) : The z axis chest acceleration during lying is lower or same as the x axis acceleration. <br>\n",
    "$H_1$(Alternate) :The z axis chest acceleration during lying is higher than the x axis acceleration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l = test[test.activity_name=='lying']\n",
    "feature1='chest_3D_acceleration_16_z'\n",
    "feature2='chest_3D_acceleration_16_x'\n",
    "test1 = test_l[feature1]\n",
    "test2 = test_l[feature2]\n",
    "print(ranksums(test1,test2,alternative='greater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we get a p-value of 0 which is lower than 0.05 we reject the null hypothesis and accept<br>\n",
    "the alternate hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 4<br>\n",
    "$H_0$(Null) : The x axis chest acceleration during running is lower or same as the z axis acceleration. <br>\n",
    "$H_1$(Alternate) :The x axis chest acceleration during lying is higher than the z axis acceleration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l = test[test.activity_name=='running']\n",
    "feature1='chest_3D_acceleration_16_x'\n",
    "feature2='chest_3D_acceleration_16_z'\n",
    "test1 = test_l[feature1]\n",
    "test2 = test_l[feature2]\n",
    "print(ranksums(test1,test2,alternative='greater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we get a p-value of 0 which is lower than 0.05 we reject the null hypothesis and accept<br>\n",
    "the alternate hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.read_pickle(\"clean_act_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects = [101,103,104,105]\n",
    "def determine_axis(feat):\n",
    "    if 'x' in feat:\n",
    "        return 'x'\n",
    "    elif 'y' in feat:\n",
    "        return 'y'\n",
    "    else:\n",
    "        return 'z'\n",
    "    \n",
    "def create_sliding_window_corr(data,win_len):\n",
    "   hand_coords = [f'hand_3D_acceleration_16_{i}' for i in ['x','y','z']] \n",
    "   chest_coords = [f'chest_3D_acceleration_16_{i}' for i in ['x','y','z']] \n",
    "   ankle_coords = [f'ankle_3D_acceleration_16_{i}' for i in ['x','y','z']] \n",
    "   def calc_corr(coords):\n",
    "      for i in itertools.combinations(coords,2):\n",
    "        ax1 = determine_axis(i[0])\n",
    "        ax2 = determine_axis(i[1])\n",
    "        coord_type = coords[0][0:5]\n",
    "        if '_' in coord_type:\n",
    "            coord_type = coord_type[:-1]\n",
    "        data[f'{coord_type}_{ax1}_{ax2}_corr']=data[\n",
    "        i[0]].rolling(win_len).corr(data[i[1]])\n",
    "      return data\n",
    "   data = calc_corr(hand_coords)\n",
    "   data = calc_corr(chest_coords)\n",
    "   data = calc_corr(ankle_coords) \n",
    "   return data\n",
    "def create_sliding_window_feats(data,feats,win_len):\n",
    "#    pca = PCA(n_components=1)\n",
    "    \n",
    "    \n",
    "   for feat in feats:\n",
    "       data[f'{feat}_roll_mean'] = data[feat].rolling(win_len).mean()\n",
    "       data[f'{feat}_roll_median'] = data[feat].rolling(win_len).mean()\n",
    "       data[f'{feat}_roll_var'] = data[feat].rolling(win_len).var()\n",
    "#        data = data.dropna()\n",
    "   return data\n",
    "   \n",
    "def train_test_split_acttype(features):\n",
    "    global clean_data\n",
    "    clean_data = clean_data.dropna()\n",
    "    train = clean_data[clean_data.id.isin(train_subjects)]\n",
    "    val = clean_data[clean_data.id.isin([102,106])]\n",
    "    test = clean_data[clean_data.id.isin([107,108])]\n",
    "    x_train = train[features]\n",
    "    x_val = val[features]\n",
    "    x_test = test[features]\n",
    "    y_train = le.fit_transform(train.activity_type)\n",
    "    y_val = le.fit_transform(val.activity_type)\n",
    "    y_test = le.fit_transform(test.activity_type)\n",
    "    return x_train,x_val,x_test,y_train,y_val,y_test\n",
    "def train_test_split_actname(features):\n",
    "    global clean_data\n",
    "    clean_data = clean_data.dropna()\n",
    "    train = clean_data[clean_data.id.isin(train_subjects)]\n",
    "    val = clean_data[clean_data.id.isin([102,106])]\n",
    "    test = clean_data[clean_data.id.isin([107,108])]\n",
    "    x_train = train[features]\n",
    "    x_val = val[features]\n",
    "    x_test = test[features]\n",
    "    y_train = le.fit_transform(train.activity_name)\n",
    "    y_val = le.fit_transform(val.activity_name)\n",
    "    y_test = le.fit_transform(test.activity_name)\n",
    "    return x_train,x_val,x_test,y_train,y_val,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_cols = [i for i in clean_data.columns if 'acceleration' in i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final=[]\n",
    "for i in clean_data.id.unique():\n",
    "   temp = clean_data[clean_data.id==i]\n",
    "   temp = create_sliding_window_feats(temp,acc_cols,256)\n",
    "   temp = create_sliding_window_corr(temp,256)\n",
    "\n",
    "   final.append(temp)\n",
    "clean_data = pd.concat(final) \n",
    "# print(clean_data[[i for i in clean_data.columns if 'roll' in i]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>hand_temperature</th>\n",
       "      <th>hand_3D_acceleration_16_x</th>\n",
       "      <th>hand_3D_acceleration_16_y</th>\n",
       "      <th>hand_3D_acceleration_16_z</th>\n",
       "      <th>hand_3D_gyroscope_x</th>\n",
       "      <th>hand_3D_gyroscope_y</th>\n",
       "      <th>hand_3D_gyroscope_z</th>\n",
       "      <th>...</th>\n",
       "      <th>ankle_3D_acceleration_16_z_roll_var</th>\n",
       "      <th>hand_x_y_corr</th>\n",
       "      <th>hand_x_z_corr</th>\n",
       "      <th>hand_y_z_corr</th>\n",
       "      <th>chest_x_y_corr</th>\n",
       "      <th>chest_x_z_corr</th>\n",
       "      <th>chest_y_z_corr</th>\n",
       "      <th>ankle_x_y_corr</th>\n",
       "      <th>ankle_x_z_corr</th>\n",
       "      <th>ankle_y_z_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>83.56</td>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>30.8125</td>\n",
       "      <td>6.01526</td>\n",
       "      <td>5.10206</td>\n",
       "      <td>5.80912</td>\n",
       "      <td>-0.034872</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>0.017553</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>83.57</td>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>30.8125</td>\n",
       "      <td>6.09325</td>\n",
       "      <td>5.06421</td>\n",
       "      <td>5.88739</td>\n",
       "      <td>-0.025281</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>83.58</td>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>30.8125</td>\n",
       "      <td>5.97881</td>\n",
       "      <td>5.10269</td>\n",
       "      <td>5.84705</td>\n",
       "      <td>-0.023323</td>\n",
       "      <td>0.016251</td>\n",
       "      <td>0.015499</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>83.59</td>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>30.8125</td>\n",
       "      <td>5.93701</td>\n",
       "      <td>4.91261</td>\n",
       "      <td>5.77010</td>\n",
       "      <td>-0.011916</td>\n",
       "      <td>0.034801</td>\n",
       "      <td>0.013740</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>83.60</td>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>30.8125</td>\n",
       "      <td>6.01580</td>\n",
       "      <td>4.98858</td>\n",
       "      <td>5.84799</td>\n",
       "      <td>-0.020812</td>\n",
       "      <td>0.016273</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872015</th>\n",
       "      <td>95.06</td>\n",
       "      <td>24</td>\n",
       "      <td>162.0</td>\n",
       "      <td>25.1250</td>\n",
       "      <td>4.99466</td>\n",
       "      <td>6.01881</td>\n",
       "      <td>5.59830</td>\n",
       "      <td>-0.289166</td>\n",
       "      <td>-0.110170</td>\n",
       "      <td>0.238570</td>\n",
       "      <td>...</td>\n",
       "      <td>10.923580</td>\n",
       "      <td>-0.427479</td>\n",
       "      <td>0.611086</td>\n",
       "      <td>-0.663470</td>\n",
       "      <td>0.500456</td>\n",
       "      <td>-0.554048</td>\n",
       "      <td>-0.603280</td>\n",
       "      <td>-0.379667</td>\n",
       "      <td>0.388499</td>\n",
       "      <td>-0.446063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872016</th>\n",
       "      <td>95.07</td>\n",
       "      <td>24</td>\n",
       "      <td>162.0</td>\n",
       "      <td>25.1250</td>\n",
       "      <td>5.02764</td>\n",
       "      <td>5.90369</td>\n",
       "      <td>5.48372</td>\n",
       "      <td>-0.275411</td>\n",
       "      <td>-0.128358</td>\n",
       "      <td>0.267409</td>\n",
       "      <td>...</td>\n",
       "      <td>10.840460</td>\n",
       "      <td>-0.431942</td>\n",
       "      <td>0.609436</td>\n",
       "      <td>-0.670327</td>\n",
       "      <td>0.501109</td>\n",
       "      <td>-0.552861</td>\n",
       "      <td>-0.604292</td>\n",
       "      <td>-0.379581</td>\n",
       "      <td>0.388055</td>\n",
       "      <td>-0.447371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872017</th>\n",
       "      <td>95.08</td>\n",
       "      <td>24</td>\n",
       "      <td>162.0</td>\n",
       "      <td>25.1250</td>\n",
       "      <td>5.06409</td>\n",
       "      <td>5.71370</td>\n",
       "      <td>5.48491</td>\n",
       "      <td>-0.289885</td>\n",
       "      <td>-0.126548</td>\n",
       "      <td>0.281483</td>\n",
       "      <td>...</td>\n",
       "      <td>10.682665</td>\n",
       "      <td>-0.466513</td>\n",
       "      <td>0.611238</td>\n",
       "      <td>-0.682667</td>\n",
       "      <td>0.498717</td>\n",
       "      <td>-0.550739</td>\n",
       "      <td>-0.603433</td>\n",
       "      <td>-0.380189</td>\n",
       "      <td>0.392554</td>\n",
       "      <td>-0.447051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872018</th>\n",
       "      <td>95.09</td>\n",
       "      <td>24</td>\n",
       "      <td>162.0</td>\n",
       "      <td>25.1250</td>\n",
       "      <td>5.13914</td>\n",
       "      <td>5.63724</td>\n",
       "      <td>5.48629</td>\n",
       "      <td>-0.234417</td>\n",
       "      <td>-0.101485</td>\n",
       "      <td>0.275497</td>\n",
       "      <td>...</td>\n",
       "      <td>10.657063</td>\n",
       "      <td>-0.498001</td>\n",
       "      <td>0.609655</td>\n",
       "      <td>-0.703511</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>-0.549184</td>\n",
       "      <td>-0.602276</td>\n",
       "      <td>-0.381009</td>\n",
       "      <td>0.392729</td>\n",
       "      <td>-0.445042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872019</th>\n",
       "      <td>95.10</td>\n",
       "      <td>24</td>\n",
       "      <td>162.0</td>\n",
       "      <td>25.1250</td>\n",
       "      <td>5.00812</td>\n",
       "      <td>5.40645</td>\n",
       "      <td>5.02326</td>\n",
       "      <td>-0.260924</td>\n",
       "      <td>-0.093849</td>\n",
       "      <td>0.266205</td>\n",
       "      <td>...</td>\n",
       "      <td>10.552733</td>\n",
       "      <td>-0.493105</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>-0.702539</td>\n",
       "      <td>0.501546</td>\n",
       "      <td>-0.547967</td>\n",
       "      <td>-0.595714</td>\n",
       "      <td>-0.375943</td>\n",
       "      <td>0.388755</td>\n",
       "      <td>-0.437095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1901562 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time_stamp  activity_id  heart_rate  hand_temperature  \\\n",
       "7518          83.56            1        93.0           30.8125   \n",
       "7519          83.57            1        93.0           30.8125   \n",
       "7520          83.58            1        93.0           30.8125   \n",
       "7521          83.59            1        93.0           30.8125   \n",
       "7522          83.60            1        93.0           30.8125   \n",
       "...             ...          ...         ...               ...   \n",
       "2872015       95.06           24       162.0           25.1250   \n",
       "2872016       95.07           24       162.0           25.1250   \n",
       "2872017       95.08           24       162.0           25.1250   \n",
       "2872018       95.09           24       162.0           25.1250   \n",
       "2872019       95.10           24       162.0           25.1250   \n",
       "\n",
       "         hand_3D_acceleration_16_x  hand_3D_acceleration_16_y  \\\n",
       "7518                       6.01526                    5.10206   \n",
       "7519                       6.09325                    5.06421   \n",
       "7520                       5.97881                    5.10269   \n",
       "7521                       5.93701                    4.91261   \n",
       "7522                       6.01580                    4.98858   \n",
       "...                            ...                        ...   \n",
       "2872015                    4.99466                    6.01881   \n",
       "2872016                    5.02764                    5.90369   \n",
       "2872017                    5.06409                    5.71370   \n",
       "2872018                    5.13914                    5.63724   \n",
       "2872019                    5.00812                    5.40645   \n",
       "\n",
       "         hand_3D_acceleration_16_z  hand_3D_gyroscope_x  hand_3D_gyroscope_y  \\\n",
       "7518                       5.80912            -0.034872             0.006905   \n",
       "7519                       5.88739            -0.025281            -0.001689   \n",
       "7520                       5.84705            -0.023323             0.016251   \n",
       "7521                       5.77010            -0.011916             0.034801   \n",
       "7522                       5.84799            -0.020812             0.016273   \n",
       "...                            ...                  ...                  ...   \n",
       "2872015                    5.59830            -0.289166            -0.110170   \n",
       "2872016                    5.48372            -0.275411            -0.128358   \n",
       "2872017                    5.48491            -0.289885            -0.126548   \n",
       "2872018                    5.48629            -0.234417            -0.101485   \n",
       "2872019                    5.02326            -0.260924            -0.093849   \n",
       "\n",
       "         hand_3D_gyroscope_z  ...  ankle_3D_acceleration_16_z_roll_var  \\\n",
       "7518                0.017553  ...                                  NaN   \n",
       "7519                0.003196  ...                                  NaN   \n",
       "7520                0.015499  ...                                  NaN   \n",
       "7521                0.013740  ...                                  NaN   \n",
       "7522                0.014696  ...                                  NaN   \n",
       "...                      ...  ...                                  ...   \n",
       "2872015             0.238570  ...                            10.923580   \n",
       "2872016             0.267409  ...                            10.840460   \n",
       "2872017             0.281483  ...                            10.682665   \n",
       "2872018             0.275497  ...                            10.657063   \n",
       "2872019             0.266205  ...                            10.552733   \n",
       "\n",
       "         hand_x_y_corr  hand_x_z_corr  hand_y_z_corr  chest_x_y_corr  \\\n",
       "7518               NaN            NaN            NaN             NaN   \n",
       "7519               NaN            NaN            NaN             NaN   \n",
       "7520               NaN            NaN            NaN             NaN   \n",
       "7521               NaN            NaN            NaN             NaN   \n",
       "7522               NaN            NaN            NaN             NaN   \n",
       "...                ...            ...            ...             ...   \n",
       "2872015      -0.427479       0.611086      -0.663470        0.500456   \n",
       "2872016      -0.431942       0.609436      -0.670327        0.501109   \n",
       "2872017      -0.466513       0.611238      -0.682667        0.498717   \n",
       "2872018      -0.498001       0.609655      -0.703511        0.499797   \n",
       "2872019      -0.493105       0.607477      -0.702539        0.501546   \n",
       "\n",
       "         chest_x_z_corr  chest_y_z_corr  ankle_x_y_corr  ankle_x_z_corr  \\\n",
       "7518                NaN             NaN             NaN             NaN   \n",
       "7519                NaN             NaN             NaN             NaN   \n",
       "7520                NaN             NaN             NaN             NaN   \n",
       "7521                NaN             NaN             NaN             NaN   \n",
       "7522                NaN             NaN             NaN             NaN   \n",
       "...                 ...             ...             ...             ...   \n",
       "2872015       -0.554048       -0.603280       -0.379667        0.388499   \n",
       "2872016       -0.552861       -0.604292       -0.379581        0.388055   \n",
       "2872017       -0.550739       -0.603433       -0.380189        0.392554   \n",
       "2872018       -0.549184       -0.602276       -0.381009        0.392729   \n",
       "2872019       -0.547967       -0.595714       -0.375943        0.388755   \n",
       "\n",
       "         ankle_y_z_corr  \n",
       "7518                NaN  \n",
       "7519                NaN  \n",
       "7520                NaN  \n",
       "7521                NaN  \n",
       "7522                NaN  \n",
       "...                 ...  \n",
       "2872015       -0.446063  \n",
       "2872016       -0.447371  \n",
       "2872017       -0.447051  \n",
       "2872018       -0.445042  \n",
       "2872019       -0.437095  \n",
       "\n",
       "[1901562 rows x 72 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_val,x_test,y_train,y_val,y_test = train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "# roll_coll=[i for i in clean_data.columns if '_roll_' in i]\n",
    "discard = ['activity_id','activity','activity_name','time_stamp', \\\n",
    "           'id','activity_type']# Columns to exclude from descriptive statistics\n",
    "features = [i for i in clean_data.columns if i not in discard]\n",
    "x_train,x_val,x_test,y_train,y_val,y_test = train_test_split_actname(\n",
    "    features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91     56425\n",
      "           1       0.50      0.86      0.63     30633\n",
      "           2       0.99      0.98      0.98     45594\n",
      "           3       0.83      0.53      0.65     26485\n",
      "           4       0.83      0.96      0.89     66624\n",
      "           5       0.99      0.94      0.97     46260\n",
      "           6       0.98      0.86      0.92     13518\n",
      "           7       0.99      0.92      0.96     32063\n",
      "           8       0.94      0.78      0.85     45386\n",
      "           9       0.78      0.81      0.79     49932\n",
      "          10       0.74      0.86      0.80     41761\n",
      "          11       0.84      0.72      0.78     58254\n",
      "\n",
      "    accuracy                           0.85    512935\n",
      "   macro avg       0.87      0.84      0.84    512935\n",
      "weighted avg       0.87      0.85      0.85    512935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "rf.fit(x_train,y_train)\n",
    "print(classification_report(y_val,rf.predict(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76     56425\n",
      "           1       0.29      0.28      0.29     30633\n",
      "           2       0.92      0.74      0.82     45594\n",
      "           3       0.61      0.40      0.48     26485\n",
      "           4       0.81      0.95      0.87     66624\n",
      "           5       0.93      0.96      0.94     46260\n",
      "           6       0.84      0.77      0.80     13518\n",
      "           7       0.94      0.93      0.93     32063\n",
      "           8       0.84      0.89      0.86     45386\n",
      "           9       0.70      0.64      0.67     49932\n",
      "          10       0.63      0.75      0.69     41761\n",
      "          11       0.62      0.77      0.69     58254\n",
      "\n",
      "    accuracy                           0.75    512935\n",
      "   macro avg       0.75      0.73      0.73    512935\n",
      "weighted avg       0.76      0.75      0.75    512935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "minmax = MinMaxScaler()\n",
    "x_train_trans=pca.transform(x_train)\n",
    "x_train_trans_scaled = minmax.fit_transform(x_train_trans)\n",
    "x_val_trans = pca.transform(x_val)\n",
    "x_val_trans_scaled = minmax.transform(x_val_trans)\n",
    "x_test_trans = pca.transform(x_test)\n",
    "x_test_trans_scaled = minmax.transform(x_test_trans)\n",
    "lr = LogisticRegression(C=10.0)\n",
    "lr.fit(x_train_trans,y_train)\n",
    "print(classification_report(y_val,lr.predict(x_val_trans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76     56425\n",
      "           1       0.30      0.28      0.29     30633\n",
      "           2       0.92      0.74      0.82     45594\n",
      "           3       0.61      0.40      0.48     26485\n",
      "           4       0.81      0.95      0.87     66624\n",
      "           5       0.93      0.96      0.94     46260\n",
      "           6       0.83      0.77      0.80     13518\n",
      "           7       0.94      0.93      0.93     32063\n",
      "           8       0.84      0.89      0.86     45386\n",
      "           9       0.70      0.64      0.67     49932\n",
      "          10       0.63      0.75      0.69     41761\n",
      "          11       0.62      0.77      0.69     58254\n",
      "\n",
      "    accuracy                           0.76    512935\n",
      "   macro avg       0.75      0.73      0.73    512935\n",
      "weighted avg       0.76      0.76      0.75    512935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val,lr.predict(x_val_trans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61165123 0.07970362 0.06070157 0.0540126  0.04214078 0.03507637\n",
      " 0.01710373 0.01634355 0.01401554 0.01313101 0.01158396]\n",
      "0.9554639615348971\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(927138, 67)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    115254\n",
       "4     109577\n",
       "8     104597\n",
       "5      94957\n",
       "9      89088\n",
       "10     87748\n",
       "0      74069\n",
       "2      70851\n",
       "1      57254\n",
       "3      57186\n",
       "7      45912\n",
       "6      20645\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(y_train)\n",
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
