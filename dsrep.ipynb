{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Research Methods Report-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**<br>\n",
    "The PAMAP2 Physical Activity Monitoring dataset (available here) contains data from 9 participants who participated in 18 various physical activities (such as walking, cycling, and soccer) while wearing three inertial measurement units (IMUs) and a heart rate monitor. This information is saved in separate text files for each subject. The goal is to build hardware and/or software that can determine the amount and type of physical activity performed by an individual by using insights derived from analysing the given dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import tabula\n",
    "from IPython.display import display\n",
    "from matplotlib import rcParams\n",
    "from scipy.stats import ranksums,ttest_ind\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view,as_strided\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "os.chdir(\"/home/sahil/Downloads/PAMAP2_Dataset/\") # Setting up working directory\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning<br>\n",
    "For tidying up the data :<br>\n",
    "- We load the data of various subjects and give relevant column names<br>\n",
    "  for various features. <br>\n",
    "- The data for all subjects are then stacked together to form one table.<br>\n",
    "- We remove the 'Orientation' columns because it was mentioned <br>\n",
    "  in the data report that it is invalid in this data collection.<br>\n",
    "- Similarly, the rows with Activity ID \"0\" are also removed as<br>\n",
    "  it does not relate to any specific activity.<br>\n",
    "- The missing values are filled up using the linear interpolation method.<br>\n",
    "- Added a new feature, 'BMI' or Body Mass Index for the 'subject_detail' table<br>\n",
    "- Additional feature, 'Activity Type' is added to the data which classifies activities <br>\n",
    "  into 3 classes, 'Light' activity,'Moderate' activity and 'Intense' activity.<br>\n",
    "  1. Lying,sitting,ironing and standing are labelled as 'light' activities.<br>\n",
    "  2. Vacuum cleaning,descending stairs,normal walking,Nordic walking and cycling are<br>\n",
    "     considered as 'Moderate' activities<br>\n",
    "  3. Ascending stairs,running and rope jumping are labelled as 'Intense' activities.  <br>\n",
    "  This classification makes it easier to perform hypothesis testing between pair of attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "Given below are functions to give relevant names to the columns and create a<br>\n",
    "single table containing data for all subjects<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_activity_names():\n",
    "    # Using this function all the activity names are mapped to their ids\n",
    "    act_name = {}\n",
    "    act_name[0] = 'transient'\n",
    "    act_name[1] = 'lying'\n",
    "    act_name[2] = 'sitting'\n",
    "    act_name[3] = 'standing'\n",
    "    act_name[4] = 'walking'\n",
    "    act_name[5] = 'running'\n",
    "    act_name[6] = 'cycling'\n",
    "    act_name[7] = 'Nordic_walking'\n",
    "    act_name[9] = 'watching_TV'\n",
    "    act_name[10] = 'computer_work'\n",
    "    act_name[11] = 'car driving'\n",
    "    act_name[12] = 'ascending_stairs'\n",
    "    act_name[13] = 'descending_stairs'\n",
    "    act_name[16] = 'vacuum_cleaning'\n",
    "    act_name[17] = 'ironing'\n",
    "    act_name[18] = 'folding_laundry'\n",
    "    act_name[19] = 'house_cleaning'\n",
    "    act_name[20] = 'playing_soccer'\n",
    "    act_name[24] = 'rope_jumping'\n",
    "    return act_name\n",
    "def generate_three_IMU(name):\n",
    "    x = name +'_x'\n",
    "    y = name +'_y'\n",
    "    z = name +'_z'\n",
    "    return [x,y,z]\n",
    "def generate_four_IMU(name):\n",
    "    x = name +'_x'\n",
    "    y = name +'_y'\n",
    "    z = name +'_z'\n",
    "    w = name +'_w'\n",
    "    return [x,y,z,w]\n",
    "def generate_cols_IMU(name):\n",
    "    # temp\n",
    "    temp = name+'_temperature'\n",
    "    output = [temp]\n",
    "    # acceleration 16\n",
    "    acceleration16 = name+'_3D_acceleration_16'\n",
    "    acceleration16 = generate_three_IMU(acceleration16)\n",
    "    output.extend(acceleration16)\n",
    "    # acceleration 6\n",
    "    acceleration6 = name+'_3D_acceleration_6'\n",
    "    acceleration6 = generate_three_IMU(acceleration6)\n",
    "    output.extend(acceleration6)\n",
    "    # gyroscope\n",
    "    gyroscope = name+'_3D_gyroscope'\n",
    "    gyroscope = generate_three_IMU(gyroscope)\n",
    "    output.extend(gyroscope)\n",
    "    # magnometer\n",
    "    magnometer = name+'_3D_magnetometer'\n",
    "    magnometer = generate_three_IMU(magnometer)\n",
    "    output.extend(magnometer)\n",
    "    # oreintation\n",
    "    oreintation = name+'_4D_orientation'\n",
    "    oreintation = generate_four_IMU(oreintation)\n",
    "    output.extend(oreintation)\n",
    "    return output\n",
    "def load_IMU():\n",
    "    output = ['time_stamp','activity_id', 'heart_rate']\n",
    "    hand = 'hand'\n",
    "    hand = generate_cols_IMU(hand)\n",
    "    output.extend(hand)\n",
    "    chest = 'chest'\n",
    "    chest = generate_cols_IMU(chest)\n",
    "    output.extend(chest)\n",
    "    ankle = 'ankle'\n",
    "    ankle = generate_cols_IMU(ankle)\n",
    "    output.extend(ankle)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subjects(root1='/home/sahil/Downloads/PAMAP2_Dataset/Protocol/subject',\n",
    "        root2 ='/home/sahil/Downloads/PAMAP2_Dataset/Optional/subject' ):\n",
    "    cols = load_IMU()\n",
    "    output = pd.DataFrame()\n",
    "    for i in range(101,110):\n",
    "        path1 = root1 + str(i) + '.dat'\n",
    "        subject= pd.DataFrame()\n",
    "         \n",
    "        subject_prot = pd.read_table(path1, header=None, sep='\\s+') # subject data from \n",
    "         # protocol activities\n",
    "        subject = subject.append(subject_prot)\n",
    "        subject.columns = cols \n",
    "        subject = subject.sort_values(by='time_stamp') # Arranging all measurements according to\n",
    "         # time\n",
    "        subject['id'] = i\n",
    "        output = output.append(subject, ignore_index=True)\n",
    "    return output\n",
    "data = load_subjects()# Add your own location for the data here to replicate the code\n",
    "# for eg data = load_subjects('filepath')\n",
    "data = data.drop(data[data['activity_id']==0].index)# Removing rows with activity id of 0\n",
    "act = gen_activity_names()\n",
    "data['activity_name'] = data.activity_id.apply(lambda x:act[x])\n",
    "data = data.drop([i for i in data.columns if 'orientation' in i], axis=1)  # Dropping Orientation  columns\n",
    "cols_6g = [i for i in data.columns if '_6_' in i] # 6g acceleration data columns\n",
    "data =  data.drop(cols_6g,axis=1) # dropping 6g acceleration columns\n",
    "display(data.head())\n",
    "# Saving transformed data in pickle format becuse it has the fastest read time compared\n",
    "# to all other formats\n",
    "data.to_pickle(\"activity_data.pkl\")  # Saving transformed data for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data,split_size):\n",
    "    np.random.seed(5)\n",
    "    msk = np.random.rand(len(data)) < split_size # This code implies (split_size*100)% of the values will be True\n",
    "    train = data[msk] # Generating training data\n",
    "    test = data[~msk] # generating testing data  \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_subjects(data): # splitting by subjects\n",
    "    subjects = [i for i in range(101,109)] # Eliminate subject 109  due to less activities\n",
    "    train_subjects = [101,103,104,105]\n",
    "    test_subjects = [i for i in subjects if i not in train_subjects]\n",
    "    train = data[data.id.isin(train_subjects)] # Generating training data\n",
    "    test = data[data.id.isin(test_subjects)] # generating testing data  \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_activities(data):\n",
    "   light = ['lying','sitting','standing','ironing'] \n",
    "   moderate = ['vacuum_cleaning','descending_stairs','normal_walking',\n",
    "           'nordic_walking','cycling']\n",
    "   intense = ['ascending_stairs','running','rope_jumping']\n",
    "   def split(activity): #  method for returning activity labels for activities\n",
    "       if activity in light:\n",
    "           return 'light'\n",
    "       elif activity in moderate:\n",
    "           return 'moderate'\n",
    "       else:\n",
    "           return 'intense'\n",
    "   data['activity_type'] = data.activity_name.apply(lambda x:split(x))\n",
    "   return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_subset(data,subset_frac): # For selecting a random subset of data\n",
    "    np.random.seed(8)\n",
    "    msk = np.random.rand(len(data)) < subset_frac # This code implies (split_size*100)% of the values will be True\n",
    "    subset = data[msk] # Generating subset\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data and doing the train-test split for EDA and Hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"activity_data.pkl\")\n",
    "data = split_by_activities(data)\n",
    "train,test = train_test_split_by_subjects(data) # train and test data for EDA and hypothesis testing respectively.\n",
    "subj_det = tabula.read_pdf(\"subjectInformation.pdf\",pages=1) # loading subject detail table from pdf file.\n",
    "# Eliminating unnecessary columns and fixing the column alignment of the table.\n",
    "sd = subj_det[0]\n",
    "new_cols = list(sd.columns)[1:9]\n",
    "sd = sd[sd.columns[0:8]]\n",
    "sd.columns = new_cols \n",
    "subj_det=sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create clean data for use in modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminate = ['activity_id','activity_name','time_stamp','id'] # Columns not meant to be cleaned\n",
    "features = [i for i in data.columns if i not in eliminate]\n",
    "clean_data = data\n",
    "clean_data[features] =clean_data[features].interpolate()\n",
    "display(clean_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After linear interpolation, the first four values of heart rate are still missing. So we fill that using back fill method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['heart_rate'] = clean_data['heart_rate'].bfill()\n",
    "display(clean_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the clean data for future use in model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.to_pickle(\"clean_act_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis<br>\n",
    "After labelling the data appropriately, we have selected 4 subjects for training set and <br>\n",
    "4 subjects for testing set such that the training and testing set have approximately equal size.<br>\n",
    "In the training set, we perform Exploratory Data Analysis and come up with potential hypotheses. <br>\n",
    "We then test those hypotheses on the testing set.<br>\n",
    "50% of data is used for training in this case(Exploratory data analysis) and the rest for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating BMI of the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_in_metres = subj_det['Height (cm)']/100\n",
    "weight_in_kg = subj_det['Weight (kg)']\n",
    "subj_det['BMI'] =  weight_in_kg/(height_in_metres)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bar chart for frequency of activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40,25\n",
    "ax=sns.countplot(x=\"activity_name\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3D scatter plot of chest acceleration coordinates for lying<br>\n",
    "<br>\n",
    "  It is expected that vertical chest acceleration will be more while lying due to the<br>\n",
    "  movements involved and an attempt is made to check this visually over here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "train_running = train[train.activity_name=='lying']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "x = train_running[\"chest_3D_acceleration_16_x\"]\n",
    "y = train_running[\"chest_3D_acceleration_16_y\"]\n",
    "z = train_running[\"chest_3D_acceleration_16_z\"]\n",
    "ax.scatter(x,y,z)\n",
    "ax.set_xlabel('X Axis')\n",
    "ax.set_ylabel('Y Axis')\n",
    "ax.set_zlabel('Z Axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   As we see, there seems to be more variance along the z axis(vertical direction) than the<br>\n",
    "   x and y axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3D scatter plot of chest acceleration coordinates for running<br>\n",
    "<br>\n",
    "  Since running involves mostly horizontal movements for the chest, we expect<br>\n",
    "  most of chest acceleration data to lie on the horizontal x amd y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "train_running = train[train.activity_name=='running']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "x = train_running[\"chest_3D_acceleration_16_x\"]\n",
    "y = train_running[\"chest_3D_acceleration_16_y\"]\n",
    "z = train_running[\"chest_3D_acceleration_16_z\"]\n",
    "ax.scatter(x,y,z)\n",
    "ax.set_xlabel('X Axis')\n",
    "ax.set_ylabel('Y Axis')\n",
    "ax.set_zlabel('Z Axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  As we expected, for running, most of the points lie along the x and y axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Time series plot of x axis chest acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "random.seed(4)\n",
    "train1 = train[train.id==random.choice(train.id.unique())]\n",
    "sns.lineplot(x='time_stamp',y='chest_3D_acceleration_16_z',hue='activity_name',data=train1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of rolling mean of vertical chest acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rolling_mean'] = train['chest_3D_acceleration_16_z'].rolling(256).mean()\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"rolling_mean\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of rolling mean of horizontal ankle acceleration along x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rolling_mean'] = train['ankle_3D_acceleration_16_x'].rolling(256).mean()\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"rolling_mean\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of rolling mean of horizontal ankle acceleration along y axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rolling_mean'] = train['ankle_3D_acceleration_16_y'].rolling(256).mean()\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"rolling_mean\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of heart rate grouped by activity type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15,10\n",
    "ax=sns.boxplot(x=\"activity_type\",y=\"heart_rate\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=0)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. We observe that moderate and intense activities have higher heart rate than<br>\n",
    "    light activities as expected.<br>\n",
    " 2. There doesn't seem to be much seperation between moderate and intesne activity<br>\n",
    "    heart rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of heart rate grouped by activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40,25\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"heart_rate\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1.  Most of the activities have a skewed distribution for heart rate.<br>\n",
    "  2. 'Nordic_walking','running' and 'cycling' have a lot of outliers on the lower side.<br>\n",
    "  3.  Activities like 'lying','sitting' and 'standing' have a lot of outliers on the upper side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of hand temperature grouped by activity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15,10\n",
    "ax=sns.boxplot(x=\"activity_type\",y=\"hand_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hand temperature of moderate activitie have a lot of outliers on the lower side.<br>\n",
    "2. There doesn't seem to be much difference in temperatures between activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of hand temperature grouped by activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40,25\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"hand_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)# Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hand temperature data of 'playing_soccer' seems to have a very pronounced positive skew.<br>\n",
    "2. \"car_driving\" and \"watching_tv\" have the least dispersion in hand temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of ankle temperature grouped by activity_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15,10\n",
    "ax=sns.boxplot(x=\"activity_type\",y=\"ankle_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ankle temperature of light and moderate activitie have  outliers on the lower side.<br>\n",
    "2. There doesn't seem to be much difference in temperatures between activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of ankle temperature grouped by activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40,25\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"ankle_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45) # Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For ankle temperature, 'playing_soccer' has the least dispersed distribution.<br>\n",
    "2. Outliers are mostly present in 'vacuum_cleaning' on the lower side. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of chest temperature grouped by activity_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15,10\n",
    "ax=sns.boxplot(x=\"activity_type\",y=\"chest_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For chest temperatures, only the 'intense' activity type has an outlier.<br>\n",
    "2. For this feature as well, there doesn't seem to be much difference between <br>\n",
    "   temperatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Boxplot of chest temperature grouped by activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 40,25\n",
    "ax=sns.boxplot(x=\"activity_name\",y=\"chest_temperature\",data=train)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45) # Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Most of the activities seem to have a skewed distribution for chest temperature.<br>\n",
    "2. 'car_driving' and 'watching_tv' seem to have the least dispersed distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A joint plot trying to investigate possibility of correlation between heart rate <br>\n",
    "  and chest temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "rcParams['font.size'] = 20 # Setting the text and number font size\n",
    "g = sns.JointGrid(data=train, x=\"heart_rate\", y=\"chest_temperature\",\n",
    "                  height=10,ratio=3)\n",
    "g.plot_joint(sns.scatterplot,palette='colorblind')\n",
    "g.plot_marginals(sns.histplot)\n",
    "# ax.set_xticklabels(ax.get_xticklabels(),rotation=45) # Rotating Text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the scatter plot, we see that there does not seem to be a correlation between<br>\n",
    "   the two variables.<br>\n",
    "2. The respective histograms indicate that both the features considered have <br>\n",
    "   a multi-modal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics<br>\n",
    "Subject Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(subj_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of heart rate and temperatures for each activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.groupby(by='activity_name')[['heart_rate','chest_temperature','hand_temperature',\n",
    "    'ankle_temperature']].mean())\n",
    "discard = ['activity_id','activity','time_stamp','id']# Columns to exclude from descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating table with only relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trimmed = train[[i for i in train.columns if i not in discard]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive info of relevant feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_trimmed.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation table of relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_trimmed.corr()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance of each axis of acceleration grouped by activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = [i for i in train.columns if 'acceleration' in i]\n",
    "display(train.groupby(by='activity_name')[coordinates].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the exploratory data analysis carried out, the following hypotheses are tested on  <br>\n",
    "the test set:<br>\n",
    "- Heart rate of moderate activities are greater than heart rate of light activities.<br>\n",
    "- Heart rate of intense activities are greater than heart rate of light activities.<br>\n",
    "- Chest acceleration along z axis is greater than that along x axis during lying.<br>\n",
    "- Chest acceleration along x axis is greater than that along z axis during running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the EDA  we performed, it does not seem that the data is normally distributed. It is <br>\n",
    "for this reason that Wilcoxon rank sum test was used to test the above hypothesis instead of the usual t-test which assumes that the samples follow a normal distribution.<br>\n",
    "We test the above hypothesis using the confidence level of 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 1<br>\n",
    "$H_0$(Null) : The heart rate during  moderate activities are the same or lower than that of light activities. <br>\n",
    "$H_1$(Alternate) : The heart rate during moderate activities are likely to be higher during lying compared to light activities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test[test.activity_type=='moderate'].heart_rate.dropna()# Heart rate of moderate activities with nan values dropped\n",
    "test2 = test[test.activity_type=='light'].heart_rate.dropna()# Heart rate of light activities with nan values dropped\n",
    "print(ranksums(test1,test2,alternative='greater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 2<br>\n",
    "$H_0$(Null) : The heart rate during intense activities are the same or lower than that of light activities. <br>\n",
    "$H_1$(Alternate) : The heart rate during intense activities are likely to be higher during than during lower activities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test[test.activity_type=='intense'].heart_rate.dropna()# Heart rate of moderate activities with nan values dropped\n",
    "test2 = test[test.activity_type=='light'].heart_rate.dropna()# Heart rate of light activities with nan values dropped\n",
    "print(ranksums(test1,test2,alternative='greater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we get a p-value of 0 which is lower than 0.05 we reject the null hypothesis and accept<br>\n",
    "the alternate hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 3<br>\n",
    "$H_0$(Null) : The z axis chest acceleration during lying is lower or same as the x axis acceleration. <br>\n",
    "$H_1$(Alternate) :The z axis chest acceleration during lying is higher than the x axis acceleration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l = test[test.activity_name=='lying']\n",
    "feature1='chest_3D_acceleration_16_z'\n",
    "feature2='chest_3D_acceleration_16_x'\n",
    "test1 = test_l[feature1]\n",
    "test2 = test_l[feature2]\n",
    "print(ranksums(test1,test2,alternative='greater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we get a p-value of 0 which is lower than 0.05 we reject the null hypothesis and accept<br>\n",
    "the alternate hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 4<br>\n",
    "$H_0$(Null) : The x axis chest acceleration during running is lower or same as the z axis acceleration. <br>\n",
    "$H_1$(Alternate) :The x axis chest acceleration during lying is higher than the z axis acceleration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l = test[test.activity_name=='running']\n",
    "feature1='chest_3D_acceleration_16_x'\n",
    "feature2='chest_3D_acceleration_16_z'\n",
    "test1 = test_l[feature1]\n",
    "test2 = test_l[feature2]\n",
    "print(ranksums(test1,test2,alternative='greater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we get a p-value of 0 which is lower than 0.05 we reject the null hypothesis and accept<br>\n",
    "the alternate hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.read_pickle(\"clean_act_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects = [101,103,104,105]\n",
    "def create_sliding_window_feats(data,feats,win_len):\n",
    "   pca = PCA(n_components=1)\n",
    "   hand_coords = [f'hand_3D_acceleration_16_{i}' for i in ['x','y','z']] \n",
    "   chest_coords = [f'chest_3D_acceleration_16_{i}' for i in ['x','y','z']] \n",
    "   ankle_coords = [f'ankle_3D_acceleration_16_{i}' for i in ['x','y','z']] \n",
    "   for feat in feats:\n",
    "       data[f'{feat}_roll_mean'] = data[feat].rolling(win_len).mean()\n",
    "       data[f'{feat}_roll_median'] = data[feat].rolling(win_len).mean()\n",
    "       data[f'{feat}_roll_var'] = data[feat].rolling(win_len).var()\n",
    "       data = data.dropna()\n",
    "   return data\n",
    "   \n",
    "def train_test_split(features):\n",
    "    train = clean_data[clean_data.id.isin(train_subjects)]\n",
    "    val = clean_data[clean_data.id.isin([102,106])]\n",
    "    test = clean_data[clean_data.id.isin([107,108])]\n",
    "    x_train = train[features]\n",
    "    x_val = val[features]\n",
    "    x_test = test[features]\n",
    "    y_train = le.fit_transform(train.activity_type)\n",
    "    y_val = le.fit_transform(val.activity_type)\n",
    "    y_test = le.fit_transform(test.activity_type)\n",
    "    return x_train,x_val,x_test,y_train,y_val,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2928      1970-01-01 00:00:37.660\n",
       "2929      1970-01-01 00:00:37.670\n",
       "2930      1970-01-01 00:00:37.680\n",
       "2931      1970-01-01 00:00:37.690\n",
       "2932      1970-01-01 00:00:37.700\n",
       "                    ...          \n",
       "2872015   1970-01-01 00:01:35.060\n",
       "2872016   1970-01-01 00:01:35.070\n",
       "2872017   1970-01-01 00:01:35.080\n",
       "2872018   1970-01-01 00:01:35.090\n",
       "2872019   1970-01-01 00:01:35.100\n",
       "Name: timestamp, Length: 1942872, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['timestamp'] = clean_data.time_stamp.apply(lambda x:\n",
    "                                                     pd.Timestamp(x,\n",
    "                                                            unit='s'))\n",
    "clean_data.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.index = clean_data.timestamp\n",
    "len(clean_data.resample('50T'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-34751b8fc2ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0.0050T'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "clean_data.resample('0.0050T')[[features]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_sliding_window_feats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5ea5a9239bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m    \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_sliding_window_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m    \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclean_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_sliding_window_feats' is not defined"
     ]
    }
   ],
   "source": [
    "acc_cols = [i for i in clean_data.columns if 'acceleration' in i] \n",
    "final=[]\n",
    "for i in clean_data.id.unique():\n",
    "   temp = clean_data[clean_data.id==i]\n",
    "   temp = create_sliding_window_feats(temp,acc_cols,256)\n",
    "   final.append(temp)\n",
    "clean_data = pd.concat(final) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "roll_coll=[i for i in clean_data.columns if '_roll_' in i]\n",
    "discard = ['activity_id','activity','activity_name','time_stamp', \\\n",
    "           'id','activity_type']# Columns to exclude from descriptive statistics\n",
    "features = [i for i in clean_data.columns if i not in discard]\n",
    "x_train,x_val,x_tes,y_train,y_val,y_test = train_test_split(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chest_coords = [f'chest_3D_acceleration_16_{i}' for i in ['x','y','z']] \n",
    "\n",
    "cd = clean_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.124482,  9.65003 , -1.65181 ],\n",
       "         [ 0.200711,  9.6498  , -1.65043 ],\n",
       "         [ 0.270277,  9.72331 , -1.88174 ],\n",
       "         ...,\n",
       "         [-2.07254 ,  9.62239 , -1.22688 ],\n",
       "         [-2.10857 ,  9.54772 , -1.14984 ],\n",
       "         [-2.18156 ,  9.47343 , -1.03476 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.200711,  9.6498  , -1.65043 ],\n",
       "         [ 0.270277,  9.72331 , -1.88174 ],\n",
       "         [ 0.236737,  9.72447 , -1.72746 ],\n",
       "         ...,\n",
       "         [-2.10857 ,  9.54772 , -1.14984 ],\n",
       "         [-2.18156 ,  9.47343 , -1.03476 ],\n",
       "         [-2.06961 ,  9.43491 , -1.11005 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.270277,  9.72331 , -1.88174 ],\n",
       "         [ 0.236737,  9.72447 , -1.72746 ],\n",
       "         [ 0.352225,  9.72437 , -1.68665 ],\n",
       "         ...,\n",
       "         [-2.18156 ,  9.47343 , -1.03476 ],\n",
       "         [-2.06961 ,  9.43491 , -1.11005 ],\n",
       "         [-1.84445 ,  9.39576 , -1.22201 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-1.1215  , -2.88318 , -1.40132 ],\n",
       "         [-1.04648 , -2.76204 , -0.161288],\n",
       "         [-1.32399 , -1.47544 ,  0.642642],\n",
       "         ...,\n",
       "         [-0.385331,  9.42255 , -2.12496 ],\n",
       "         [-0.273773,  9.23341 , -2.19977 ],\n",
       "         [-0.23526 ,  9.3839  , -2.19956 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.04648 , -2.76204 , -0.161288],\n",
       "         [-1.32399 , -1.47544 ,  0.642642],\n",
       "         [-0.83521 , -0.123793,  0.298616],\n",
       "         ...,\n",
       "         [-0.273773,  9.23341 , -2.19977 ],\n",
       "         [-0.23526 ,  9.3839  , -2.19956 ],\n",
       "         [-0.125392,  9.42016 , -2.35257 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.32399 , -1.47544 ,  0.642642],\n",
       "         [-0.83521 , -0.123793,  0.298616],\n",
       "         [ 0.544037,  2.13138 ,  0.354994],\n",
       "         ...,\n",
       "         [-0.23526 ,  9.3839  , -2.19956 ],\n",
       "         [-0.125392,  9.42016 , -2.35257 ],\n",
       "         [-0.195902,  9.4217  , -2.16025 ]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = sliding_window_view(cd[chest_coords],(256,3))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strided_app( a, L=256, S=100):  # Window len = L, Stride len/stepsize = S\n",
    "        \n",
    "        return np.lib.stride_tricks.as_strided(a,strides=(1,100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 15542976)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cd[chest_coords]).strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1942872, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cd[chest_coords]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection \n",
    "\n",
    "def new_dim(data):\n",
    "    rng = np.random.RandomState(42)\n",
    "    X = data\n",
    "    transformer = GaussianRandomProjection(random_state=rng,\n",
    "                                           n_components=1)\n",
    "    X_new = transformer.fit_transform(data.reshape(256,3))\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
